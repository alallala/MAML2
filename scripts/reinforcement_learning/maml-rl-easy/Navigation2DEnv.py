import gym
import numpy as np
from gym import spaces
from gym.utils import seeding
from gym.envs.classic_control import rendering


class Navigation2DEnv(gym.Env):
    """2D navigation problems, as described in [1]. The code is adapted from 
    https://github.com/cbfinn/maml_rl/blob/9c8e2ebd741cb0c7b8bf2d040c4caeeb8e06cc95/maml_examples/point_env_randgoal.py

    At each time step, the 2D agent takes an action (its velocity, clipped in
    [-0.1, 0.1]), and receives a penalty equal to its L2 distance to the goal 
    position (ie. the reward is `-distance`). The 2D navigation tasks are 
    generated by sampling goal positions from the uniform distribution 
    on [-0.5, 0.5]^2.

    [1] Chelsea Finn, Pieter Abbeel, Sergey Levine, "Model-Agnostic 
        Meta-Learning for Fast Adaptation of Deep Networks", 2017 
        (https://arxiv.org/abs/1703.03400)
    """
    def __init__(self, task={}):
        super(Navigation2DEnv, self).__init__()

        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,
            shape=(2,), dtype=np.float32)
        self.action_space = spaces.Box(low=-0.1, high=0.1,
            shape=(2,), dtype=np.float32)

        self.viewer = None

        self._task = task
        self._goal = task.get('goal', np.zeros(2, dtype=np.float32))
        self._state = np.zeros(2, dtype=np.float32)
        self.seed()

    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def sample_tasks(self, num_tasks):
        goals = self.np_random.uniform(-0.5, 0.5, size=(num_tasks, 2))
        tasks = [{'goal': goal} for goal in goals]
        return tasks

    def reset_task(self, task):
        self._task = task
        self._goal = task['goal']

    def reset(self, env=True):
        self._state = np.zeros(2, dtype=np.float32)
        return self._state

    def step(self, action):
        action = np.clip(action, -0.1, 0.1)
        assert self.action_space.contains(action), f"Action {action} not in the action space"
        self._state = self._state + action

        x = self._state[0] - self._goal[0]
        y = self._state[1] - self._goal[1]
        reward = -np.sqrt(x ** 2 + y ** 2)
        done = bool((np.abs(x) < 0.01) and (np.abs(y) < 0.01))

        return self._state, reward, done, self._task

    def render(self, mode='rgb_array'):
        screen_width = 500
        screen_height = 500

        print (self._state)

        if self.viewer is None:
            self._last_state = (0,0)
            
            # Initialize Viewer
            self.viewer = rendering.Viewer(screen_width, screen_height)
            '''
            The coordinate system in rendering looks like:
            ==============================================
            (0,y)

            (0,0)    (x,0)
            ==============================================
            '''
            # Create coordinate system
            self.x_axis = rendering.Line((0,250),(500,250))
            self.y_axis = rendering.Line((250,0), (250,500))
            self.x_axis.set_color(0,0,0)
            self.y_axis.set_color(0,0,0)
            self.viewer.add_geom(self.x_axis)
            self.viewer.add_geom(self.y_axis)

            # Create goal point
            self.goal_point = rendering.make_circle(2)
            self.goal_trans = rendering.Transform(translation=(int((self._goal[0]+0.5)*500), int((self._goal[1]+0.5)*500)))
            self.goal_point.add_attr(self.goal_trans)
            self.goal_point.set_color(0.25, 0.42, 0.88)
            self.viewer.add_geom(self.goal_point)

            # Create current state
            self.state_point = rendering.make_circle(2)
            self.state_trans = rendering.Transform(translation=(int((self._state[0]+0.5)*500), int((self._state[1]+0.5)*500)))
            self.state_point.add_attr(self.state_trans)
            self.state_point.set_color(1, 0.49, 0.31)
            self.viewer.add_geom(self.state_point)
        
        # Update rendering for each step
        cur_pos = self._state
        last_pos = self._last_state
        self.state_trans.set_translation(int((self._state[0]+0.5)*500), int((self._state[1]+0.5)*500))
        self.trace = rendering.Line(((last_pos[0]+0.5)*500, (last_pos[1]+0.5)*500), ((cur_pos[0]+0.5)*500, (cur_pos[1]+0.5)*500))
        self.trace.set_color(1, 0.49, 0.31)
        self.viewer.add_geom(self.trace)
        self._last_state = self._state
        
        return self.viewer.render(return_rgb_array = mode == 'rgb_array')

        

